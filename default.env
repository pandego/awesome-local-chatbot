# ---------------------------- #
# --- Ollama Configuration --- #
# ---------------------------- #

OLLAMA_BASE_URL='http://localhost:11434'
OLLAMA_VERSION='0.11.11'  # 'latest'
OLLAMA_PORT='11434'
OLLAMA_DATA_DIR='~/data/ollama'
MODEL_NAME='llama3.1'
OLLAMA_NUM_PARALLEL='4'
OLLAMA_MAX_LOADED_MODELS='2'

# ----------------------------------- #
# --- Automatic1111 Configuration --- #
# ----------------------------------- #

AUTOMATIC1111_BASE_URL='http://localhost:7860'
AUTOMATIC1111_PORT='7860'
AUTOMATIC1111_MODEL_DIR='~/data/sd-webui-auto1111/models/Stable-diffusion'
AUTOMATIC1111_OUTPUT_DIR='~/data/sd-webui-auto1111/output'
AUTOMATIC1111_VERSION='1.9.4'  

# -------------------------------- #
# --- Open WebUI Configuration --- #
# -------------------------------- #

OPEN_WEBUI_PORT='3000'
OPEN_WEBUI_VERSION='0.6.28'  # 'latest'
OPEN_WEBUI_DATA_DIR='~/data/open-webui'

# CUSTOMIZE WEBUI
WEBUI_NAME='Dogito Bot üê∂'
CUSTOM_NAME='Dogito Bot üê∂'
CUSTOM_FAVICON_DIR=favicon.png

# DO NOT TRACK
SCARF_NO_ANALYTICS='True'
DO_NOT_TRACK='True'
ANONYMIZED_TELEMETRY='True'

# Use locally bundled version of the LiteLLM cost map json
# to avoid repetitive startup connections
# LITELLM_LOCAL_MODEL_COST_MAP="True"

# --------------------------------------- #
# --- OpenAI Compatible Configuration --- #
# --------------------------------------- #

# OPENAI
# OPENAI_API_BASE_URL='https://api.openai.com/v1'
# OPENAI_API_KEY='sk-'

# GROQ
# OPENAI_API_BASE_URL='https://api.groq.com/openai/v1'
# GROQ_API_TOKEN='qsk-'

# ------------------ #
# --- Web Search --- #
# ------------------ #

# TAVILY_API_KEY='tvly-'
